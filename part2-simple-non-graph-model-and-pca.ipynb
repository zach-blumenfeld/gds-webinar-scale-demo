{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750e7f38",
   "metadata": {},
   "source": [
    "# Part 2: \"Flat\" Model  - Logistic Regression with RoBERTa Encodings and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6664d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cbb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea8f478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_encoding_0</th>\n",
       "      <th>paper_encoding_1</th>\n",
       "      <th>paper_encoding_2</th>\n",
       "      <th>paper_encoding_3</th>\n",
       "      <th>paper_encoding_4</th>\n",
       "      <th>paper_encoding_5</th>\n",
       "      <th>paper_encoding_6</th>\n",
       "      <th>paper_encoding_7</th>\n",
       "      <th>paper_encoding_8</th>\n",
       "      <th>paper_encoding_9</th>\n",
       "      <th>...</th>\n",
       "      <th>paper_encoding_761</th>\n",
       "      <th>paper_encoding_762</th>\n",
       "      <th>paper_encoding_763</th>\n",
       "      <th>paper_encoding_764</th>\n",
       "      <th>paper_encoding_765</th>\n",
       "      <th>paper_encoding_766</th>\n",
       "      <th>paper_encoding_767</th>\n",
       "      <th>split_segment</th>\n",
       "      <th>paper_subject</th>\n",
       "      <th>paper_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438477</td>\n",
       "      <td>0.211060</td>\n",
       "      <td>0.393311</td>\n",
       "      <td>0.055969</td>\n",
       "      <td>-0.078003</td>\n",
       "      <td>-0.017807</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>-0.319824</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>0.502930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052490</td>\n",
       "      <td>1.092773</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>-1.467773</td>\n",
       "      <td>-1.590820</td>\n",
       "      <td>0.328613</td>\n",
       "      <td>0.332275</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.468994</td>\n",
       "      <td>-0.202637</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.496582</td>\n",
       "      <td>0.024368</td>\n",
       "      <td>0.239990</td>\n",
       "      <td>0.539551</td>\n",
       "      <td>0.460449</td>\n",
       "      <td>0.078491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>1.125977</td>\n",
       "      <td>0.368164</td>\n",
       "      <td>-0.191406</td>\n",
       "      <td>-0.378418</td>\n",
       "      <td>0.031616</td>\n",
       "      <td>-0.311523</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047485</td>\n",
       "      <td>-0.398682</td>\n",
       "      <td>-0.420410</td>\n",
       "      <td>0.882324</td>\n",
       "      <td>-0.114685</td>\n",
       "      <td>0.607910</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>-0.012108</td>\n",
       "      <td>-0.005211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130127</td>\n",
       "      <td>-0.121155</td>\n",
       "      <td>0.790527</td>\n",
       "      <td>-0.147827</td>\n",
       "      <td>-0.451904</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>-0.135986</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.395508</td>\n",
       "      <td>-0.464355</td>\n",
       "      <td>-0.336670</td>\n",
       "      <td>-0.156616</td>\n",
       "      <td>-0.396240</td>\n",
       "      <td>-0.449951</td>\n",
       "      <td>-0.033630</td>\n",
       "      <td>0.393066</td>\n",
       "      <td>0.552246</td>\n",
       "      <td>-0.076782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149780</td>\n",
       "      <td>1.133789</td>\n",
       "      <td>0.386230</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.760742</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>-0.658691</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103210</td>\n",
       "      <td>-0.125122</td>\n",
       "      <td>0.039490</td>\n",
       "      <td>0.651855</td>\n",
       "      <td>0.279053</td>\n",
       "      <td>0.020828</td>\n",
       "      <td>0.325439</td>\n",
       "      <td>-0.004528</td>\n",
       "      <td>0.264404</td>\n",
       "      <td>0.178101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056824</td>\n",
       "      <td>0.499023</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>-0.623047</td>\n",
       "      <td>-0.119080</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138944</th>\n",
       "      <td>-0.254883</td>\n",
       "      <td>-0.069885</td>\n",
       "      <td>-0.821289</td>\n",
       "      <td>1.201172</td>\n",
       "      <td>-0.639160</td>\n",
       "      <td>-0.368164</td>\n",
       "      <td>0.802246</td>\n",
       "      <td>-0.076355</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>0.030365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.697754</td>\n",
       "      <td>0.369629</td>\n",
       "      <td>1.799805</td>\n",
       "      <td>-0.534180</td>\n",
       "      <td>-0.112244</td>\n",
       "      <td>-0.230713</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138945</th>\n",
       "      <td>0.667480</td>\n",
       "      <td>-0.046448</td>\n",
       "      <td>0.194214</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.495361</td>\n",
       "      <td>0.756348</td>\n",
       "      <td>-0.065125</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>0.123657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.436279</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>0.360596</td>\n",
       "      <td>-1.391602</td>\n",
       "      <td>-0.752930</td>\n",
       "      <td>-0.068970</td>\n",
       "      <td>0.195923</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138946</th>\n",
       "      <td>0.660645</td>\n",
       "      <td>-0.515137</td>\n",
       "      <td>-0.776367</td>\n",
       "      <td>0.222412</td>\n",
       "      <td>-1.073242</td>\n",
       "      <td>0.049652</td>\n",
       "      <td>0.335205</td>\n",
       "      <td>0.281982</td>\n",
       "      <td>1.385742</td>\n",
       "      <td>0.360840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331787</td>\n",
       "      <td>-0.043549</td>\n",
       "      <td>0.609863</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>0.211304</td>\n",
       "      <td>0.060333</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138947</th>\n",
       "      <td>0.427246</td>\n",
       "      <td>-0.276855</td>\n",
       "      <td>-0.203857</td>\n",
       "      <td>0.391113</td>\n",
       "      <td>-0.368896</td>\n",
       "      <td>-0.091003</td>\n",
       "      <td>1.030273</td>\n",
       "      <td>0.415039</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.121399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198730</td>\n",
       "      <td>1.151367</td>\n",
       "      <td>0.054382</td>\n",
       "      <td>-0.266113</td>\n",
       "      <td>-0.600098</td>\n",
       "      <td>0.258057</td>\n",
       "      <td>0.411377</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138948</th>\n",
       "      <td>0.123779</td>\n",
       "      <td>-0.914551</td>\n",
       "      <td>-0.064758</td>\n",
       "      <td>0.073181</td>\n",
       "      <td>-0.243286</td>\n",
       "      <td>-0.610840</td>\n",
       "      <td>0.522461</td>\n",
       "      <td>-0.022171</td>\n",
       "      <td>-0.621094</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159180</td>\n",
       "      <td>0.350342</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>-0.407715</td>\n",
       "      <td>-0.976562</td>\n",
       "      <td>0.545410</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251341 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_encoding_0  paper_encoding_1  paper_encoding_2  \\\n",
       "index                                                          \n",
       "0               0.438477          0.211060          0.393311   \n",
       "1               0.468994         -0.202637          0.023331   \n",
       "2               0.047485         -0.398682         -0.420410   \n",
       "3              -0.395508         -0.464355         -0.336670   \n",
       "4               0.103210         -0.125122          0.039490   \n",
       "...                  ...               ...               ...   \n",
       "138944         -0.254883         -0.069885         -0.821289   \n",
       "138945          0.667480         -0.046448          0.194214   \n",
       "138946          0.660645         -0.515137         -0.776367   \n",
       "138947          0.427246         -0.276855         -0.203857   \n",
       "138948          0.123779         -0.914551         -0.064758   \n",
       "\n",
       "        paper_encoding_3  paper_encoding_4  paper_encoding_5  \\\n",
       "index                                                          \n",
       "0               0.055969         -0.078003         -0.017807   \n",
       "1               0.535645          0.496582          0.024368   \n",
       "2               0.882324         -0.114685          0.607910   \n",
       "3              -0.156616         -0.396240         -0.449951   \n",
       "4               0.651855          0.279053          0.020828   \n",
       "...                  ...               ...               ...   \n",
       "138944          1.201172         -0.639160         -0.368164   \n",
       "138945          0.251953          0.003784          0.495361   \n",
       "138946          0.222412         -1.073242          0.049652   \n",
       "138947          0.391113         -0.368896         -0.091003   \n",
       "138948          0.073181         -0.243286         -0.610840   \n",
       "\n",
       "        paper_encoding_6  paper_encoding_7  paper_encoding_8  \\\n",
       "index                                                          \n",
       "0               0.553223         -0.319824          0.394043   \n",
       "1               0.239990          0.539551          0.460449   \n",
       "2               0.151001          0.124695         -0.012108   \n",
       "3              -0.033630          0.393066          0.552246   \n",
       "4               0.325439         -0.004528          0.264404   \n",
       "...                  ...               ...               ...   \n",
       "138944          0.802246         -0.076355          0.324219   \n",
       "138945          0.756348         -0.065125         -0.071777   \n",
       "138946          0.335205          0.281982          1.385742   \n",
       "138947          1.030273          0.415039          0.506836   \n",
       "138948          0.522461         -0.022171         -0.621094   \n",
       "\n",
       "        paper_encoding_9  ...  paper_encoding_761  paper_encoding_762  \\\n",
       "index                     ...                                           \n",
       "0               0.502930  ...           -0.052490            1.092773   \n",
       "1               0.078491  ...           -0.132812            1.125977   \n",
       "2              -0.005211  ...           -0.130127           -0.121155   \n",
       "3              -0.076782  ...            0.149780            1.133789   \n",
       "4               0.178101  ...            0.056824            0.499023   \n",
       "...                  ...  ...                 ...                 ...   \n",
       "138944          0.030365  ...            0.553223            0.697754   \n",
       "138945          0.123657  ...           -0.436279            1.187500   \n",
       "138946          0.360840  ...           -0.331787           -0.043549   \n",
       "138947          0.121399  ...           -0.198730            1.151367   \n",
       "138948          0.040161  ...           -0.159180            0.350342   \n",
       "\n",
       "        paper_encoding_763  paper_encoding_764  paper_encoding_765  \\\n",
       "index                                                                \n",
       "0                 0.157227           -1.467773           -1.590820   \n",
       "1                 0.368164           -0.191406           -0.378418   \n",
       "2                 0.790527           -0.147827           -0.451904   \n",
       "3                 0.386230            0.066162            0.760742   \n",
       "4                 0.038788            0.906250           -0.623047   \n",
       "...                    ...                 ...                 ...   \n",
       "138944            0.369629            1.799805           -0.534180   \n",
       "138945            0.360596           -1.391602           -0.752930   \n",
       "138946            0.609863            0.025223            0.232422   \n",
       "138947            0.054382           -0.266113           -0.600098   \n",
       "138948           -0.007122           -0.407715           -0.976562   \n",
       "\n",
       "        paper_encoding_766  paper_encoding_767  split_segment  paper_subject  \\\n",
       "index                                                                          \n",
       "0                 0.328613            0.332275          TRAIN           17.0   \n",
       "1                 0.031616           -0.311523          TRAIN           29.0   \n",
       "2                 0.516602           -0.135986          TRAIN           38.0   \n",
       "3                 0.355469           -0.658691          TRAIN            5.0   \n",
       "4                -0.119080            0.394043          TRAIN            1.0   \n",
       "...                    ...                 ...            ...            ...   \n",
       "138944           -0.112244           -0.230713       VALIDATE           51.0   \n",
       "138945           -0.068970            0.195923       VALIDATE           12.0   \n",
       "138946            0.211304            0.060333       VALIDATE           18.0   \n",
       "138947            0.258057            0.411377       VALIDATE           72.0   \n",
       "138948            0.545410            0.017975       VALIDATE          142.0   \n",
       "\n",
       "        paper_year  \n",
       "index               \n",
       "0             2014  \n",
       "1             2014  \n",
       "2             2015  \n",
       "3             2005  \n",
       "4             2013  \n",
       "...            ...  \n",
       "138944        2019  \n",
       "138945        2019  \n",
       "138946        2019  \n",
       "138947        2019  \n",
       "138948        2019  \n",
       "\n",
       "[1251341 rows x 771 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df = pd.read_parquet(ROOT_DATA_DIR + \"/ogb-labeled-papers.parquet\", engine='fastparquet')\n",
    "papers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbbff1",
   "metadata": {},
   "source": [
    "## Data Split and Subject Label Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b27e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_encoding_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_segment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN</th>\n",
       "      <td>1112392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALIDATE</th>\n",
       "      <td>138949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               paper_encoding_0\n",
       "split_segment                  \n",
       "TRAIN                   1112392\n",
       "VALIDATE                 138949"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df[['split_segment', 'paper_encoding_0']].groupby('split_segment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e94ffa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_encoding_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_subject</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>28041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148.0</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149.0</th>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150.0</th>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151.0</th>\n",
       "      <td>22696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152.0</th>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               paper_encoding_0\n",
       "paper_subject                  \n",
       "0.0                       28041\n",
       "1.0                        2856\n",
       "2.0                        3907\n",
       "3.0                        1530\n",
       "4.0                        1910\n",
       "...                         ...\n",
       "148.0                       865\n",
       "149.0                       815\n",
       "150.0                       837\n",
       "151.0                     22696\n",
       "152.0                      1139\n",
       "\n",
       "[153 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df[['paper_subject', 'paper_encoding_0']].groupby('paper_subject').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88beb827",
   "metadata": {},
   "source": [
    "## Logistic Regression Using Entire 768 Dimensional Encoding\n",
    "\n",
    "\n",
    "As a first pass we will try to fit this model with simple logistic regression using just the 768 dimensional RoBERTa encoding vectors as features. \n",
    "\n",
    "__Note: this model fitting step can take a while (several hours) to complete__\n",
    "\n",
    "We will get convergence warnings when running the below model model.  I tried various different parameters to try and avoid this in sklearn but could not seem to do so. In a more rigorous setting I would recommend looking deeper into tuning parameters, different model types, different machine learning libraries/frameworks, etc. But for purposes of this demo we are just trying to get an initial rough benchmark. In the following sections we will apply a very simple solution of dimensionality reduction with Principal Components Analysis (PCA) to see the effect on results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8a82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df = papers_df.astype({'paper_subject':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4863519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = papers_df[['paper_encoding_' + str(x) for x in range(768)]]\n",
    "y = papers_df.paper_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486dfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[papers_df.split_segment == \"TRAIN\"]\n",
    "X_validate = X[papers_df.split_segment == \"VALIDATE\"]\n",
    "y_train = y[papers_df.split_segment == \"TRAIN\"]\n",
    "y_validate = y[papers_df.split_segment == \"VALIDATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d95251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='ovr', solver='saga', n_jobs=60, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91cba657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.conda/envs/graph2/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, multi_class='ovr', n_jobs=60, solver='saga')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: This can take a while (several hours)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a826e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on VALIDATE set: 0.49\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on VALIDATE set: {:.2f}'\\\n",
    "      .format(model.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67621ceb",
   "metadata": {},
   "source": [
    "## Reducing Dimensionality with Principal Components Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cea5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcbf2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "plt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb6a41",
   "metadata": {},
   "source": [
    "Note that almost 93% of the variance is explained by the first 128 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7005d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9270989465518304"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_[:128])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade6a55",
   "metadata": {},
   "source": [
    "## Logistic Regression with 128 Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d55936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.19892061e-01,  7.57744837e+00,  2.38994151e-01, ...,\n",
       "         1.45125136e-01,  4.76339161e-01, -3.43906790e-01],\n",
       "       [ 1.02952302e+00,  4.56361294e+00,  1.81073594e+00, ...,\n",
       "        -3.10825527e-01, -1.21716559e-01, -1.96754932e-03],\n",
       "       [ 1.57442674e-01,  4.48937798e+00, -2.28051734e+00, ...,\n",
       "         1.97405860e-01,  4.04985249e-01, -6.72422767e-01],\n",
       "       ...,\n",
       "       [-7.67455101e+00, -1.38447428e+00,  3.48542595e+00, ...,\n",
       "        -1.10648334e-01, -3.42456937e-01, -4.07753110e-01],\n",
       "       [-7.29859233e-01, -1.26016960e-02,  1.33440959e+00, ...,\n",
       "        -3.93246353e-01, -2.03127354e-01, -8.12449753e-02],\n",
       "       [ 2.64888406e+00,  2.00736737e+00, -2.70441365e+00, ...,\n",
       "         1.83935657e-01, -3.53981048e-01, -3.53198677e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca128 = PCA(n_components=128)\n",
    "pca128.fit(X_train)\n",
    "X_train_reduced = pca128.transform(X_train)\n",
    "X_train_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25a7041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_128 = LogisticRegression(multi_class='ovr', solver='saga', n_jobs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffa7a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', n_jobs=60, solver='saga')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_128.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e3734fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_reduced = pca128.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6617d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on VALIDATE set: 0.43\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on VALIDATE set: {:.2f}'\\\n",
    "      .format(model_128.score(X_validate_reduced, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2ca0d",
   "metadata": {},
   "source": [
    "__Accuracy seems to go down, though we seem to have avoided convergence warnings__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406d1e1",
   "metadata": {},
   "source": [
    "### Save PCA Object\n",
    "We will use this in part 3 for Neo4j import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "346f767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/paper-feat-pca128.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(pca128, ROOT_DATA_DIR + '/paper-feat-pca128.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb06747",
   "metadata": {},
   "source": [
    "## (Optional) Checking with 384 Principal Components\n",
    "Just for sake of experimentation, let's up the dimensionality to 384 (50% the size of the original vector size) and see what we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8209bcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850090609327055"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_[:384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e67dcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.19884431e-01,  7.57744980e+00,  2.38999844e-01, ...,\n",
       "        -2.00414509e-02,  1.23605132e-02,  5.13292551e-02],\n",
       "       [ 1.02952719e+00,  4.56361008e+00,  1.81073332e+00, ...,\n",
       "        -1.46002211e-02,  1.11485720e-02, -6.50432706e-03],\n",
       "       [ 1.57447502e-01,  4.48937893e+00, -2.28051710e+00, ...,\n",
       "        -1.08808234e-01,  5.55179715e-02,  1.12585865e-01],\n",
       "       ...,\n",
       "       [-7.67455006e+00, -1.38446569e+00,  3.48541903e+00, ...,\n",
       "         7.78694451e-02,  4.36903536e-02, -1.50039345e-01],\n",
       "       [-7.29859591e-01, -1.26056150e-02,  1.33440888e+00, ...,\n",
       "        -1.61436945e-02, -1.19892642e-01, -2.25727051e-01],\n",
       "       [ 2.64888358e+00,  2.00736547e+00, -2.70441127e+00, ...,\n",
       "        -6.14562258e-02,  7.74844512e-02, -3.82103026e-05]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca384 = PCA(n_components=384)\n",
    "pca384.fit(X_train)\n",
    "X_train_reduced_384 = pca384.transform(X_train)\n",
    "X_train_reduced_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1489fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_384 = LogisticRegression(multi_class='ovr', solver='saga', n_jobs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67c70089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', n_jobs=60, solver='saga')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_384.fit(X_train_reduced_384, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "177b2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_reduced_384 = pca384.transform(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c58f21af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on VALIDATE set: 0.47\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on VALIDATE set: {:.2f}'\\\n",
    "      .format(model_384.score(X_validate_reduced_384, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef1bbe8",
   "metadata": {},
   "source": [
    "__Very close to the original accuracy but still lower__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c7c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
